{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load reqruired libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "import params\n",
    "\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_at):\n",
    "    df = pd.read_csv(data_at)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Encoding the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_data(X_train, X_valid, X_test, y_train, y_valid, y_test):\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_valid = y_valid.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    train_data = pd.DataFrame(np.concatenate((X_train, y_train), axis=1))\n",
    "    valid_data = pd.DataFrame(np.concatenate((X_valid, y_valid), axis=1))\n",
    "    test_data = pd.DataFrame(np.concatenate((X_test, y_test), axis=1))\n",
    "\n",
    "    train_data_at = wandb.Artifact(params.TRAIN_DATA_AT, type='train_data')\n",
    "    train_data_at.add(wandb.Table(dataframe=train_data_at), 'train_data')\n",
    "\n",
    "    valid_data_at = wandb.Artifact(params.VALID_DATA_AT, type='valid_data')\n",
    "    valid_data_at.add(wandb.Table(dataframe=valid_data_at), 'valid_data')\n",
    "\n",
    "    test_data_at = wandb.Artifact(params.TEST_DATA_AT, type='test_data')\n",
    "    test_data_at.add(wandb.Table(dataframe=test_data_at), 'test_data')\n",
    "\n",
    "    wandb.log_artifact(train_data_at)\n",
    "    wandb.log_artifact(valid_data_at)\n",
    "    wandb.log_artifact(test_data_at)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    target_encoder = OrdinalEncoder(encoding_method='arbitrary', variables='Accident_severity')\n",
    "    df = target_encoder.fit_transform(df)\n",
    "\n",
    "    X = df.drop('Accident_severity', axis=1).values\n",
    "    y = df['Accident_severity'].values\n",
    "\n",
    "    # Initialize the StratifiedShuffleSplit object\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Split for train and temp (which will be further divided into validation and test)\n",
    "    for train_index, temp_index in sss.split(X, y):\n",
    "        X_train, X_temp = X[train_index], X[temp_index]\n",
    "        y_train, y_temp = y[train_index], y[temp_index]\n",
    "\n",
    "    # Now split the temp data into validation and test sets\n",
    "    sss_valid_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "    for valid_index, test_index in sss_valid_test.split(X_temp, y_temp):\n",
    "        X_valid, X_test = X_temp[valid_index], X_temp[test_index]\n",
    "        y_valid, y_test = y_temp[valid_index], y_temp[test_index]\n",
    "\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictions(y_true, y_pred, name):\n",
    "    df = pd.DataFrame({\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "    # Create a wandb.Table\n",
    "    table = wandb.Table(dataframe=df)\n",
    "    # Log the table\n",
    "    wandb.log({name: table})\n",
    "\n",
    "\n",
    "def log_metrics(y_true, y_pred, name):\n",
    "\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    classification_report_ = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    # Create a wandb.Table\n",
    "    table = wandb.Table(dataframe=pd.DataFrame(classification_report_).transpose())\n",
    "    # Log the table\n",
    "    wandb.log({name: table})\n",
    "    wandb.log({name + \"_rmse\": rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkrishnatasya\u001b[0m (\u001b[33mblack-order\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\krish\\Documents\\Projects\\TMLC\\AccidentSeverity\\wandb\\run-20230521_104124-t3ms1613</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/black-order/accident-severity-prediction/runs/t3ms1613' target=\"_blank\">apricot-pond-10</a></strong> to <a href='https://wandb.ai/black-order/accident-severity-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/black-order/accident-severity-prediction' target=\"_blank\">https://wandb.ai/black-order/accident-severity-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/black-order/accident-severity-prediction/runs/t3ms1613' target=\"_blank\">https://wandb.ai/black-order/accident-severity-prediction/runs/t3ms1613</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_rmse</td><td>▁</td></tr><tr><td>valid_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_rmse</td><td>0.43019</td></tr><tr><td>valid_rmse</td><td>0.44594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-pond-10</strong> at: <a href='https://wandb.ai/black-order/accident-severity-prediction/runs/t3ms1613' target=\"_blank\">https://wandb.ai/black-order/accident-severity-prediction/runs/t3ms1613</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230521_104124-t3ms1613\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a config dictionary object\n",
    "config = {\n",
    "  \"random_state\": 2022,\n",
    "    \"max_depth\": 2\n",
    "}\n",
    "\n",
    "def train(config):\n",
    "\n",
    "    # WANDB RUN\n",
    "    run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training-xgboost\", config=config)\n",
    "    config = wandb.config\n",
    "\n",
    "    # Load the data\n",
    "    df = load_data(\"data/RTA Dataset Transformed.csv\")\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = preprocess_data(df)\n",
    "    \n",
    "    # Train the model\n",
    "    xgboost = xgb.XGBClassifier(random_state=wandb.config['random_state'], \n",
    "                                max_depth=wandb.config['max_depth'])\n",
    "    \n",
    "    xgboost = xgboost.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation predictions\n",
    "    y_pred = xgboost.predict(X_valid)\n",
    "    # log the predictions\n",
    "    log_predictions(y_valid, y_pred, name='valid')\n",
    "\n",
    "    # Test predictions\n",
    "    y_pred = xgboost.predict(X_test)\n",
    "    # log the predictions \n",
    "    log_predictions(y_test, y_pred, name='test')\n",
    "\n",
    "    # Log the metrics\n",
    "    log_metrics(y_valid, y_pred, name='valid')\n",
    "    log_metrics(y_test, y_pred, name='test')\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
